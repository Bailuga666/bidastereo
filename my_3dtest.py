# full_version_check.pyï¼ˆé€‚é…PyTorch 1.12.1ï¼‰
import torch
import platform
import subprocess
import os

def run_command(cmd):
    """æ‰§è¡Œç»ˆç«¯å‘½ä»¤å¹¶è¿”å›è¾“å‡º"""
    try:
        result = subprocess.check_output(cmd, shell=True, stderr=subprocess.STDOUT)
        return result.decode('utf-8').strip()
    except subprocess.CalledProcessError as e:
        return f"å‘½ä»¤æ‰§è¡Œå¤±è´¥: {e.output.decode('utf-8').strip()}"

def check_all_versions():
    print("=== ğŸ” å…¨é“¾è·¯ç‰ˆæœ¬æ£€æµ‹æŠ¥å‘Š ===")
    
    # 1. ç³»ç»Ÿ/ç¯å¢ƒåŸºç¡€ä¿¡æ¯
    print("\nã€1. ç³»ç»Ÿä¸WSLä¿¡æ¯ã€‘")
    print(f"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
    print(f"Pythonç‰ˆæœ¬: {platform.python_version()}")
    print(f"WSLç‰ˆæœ¬æ£€æµ‹ï¼ˆWindows PowerShellå‘½ä»¤ï¼ŒWSLå†…æ‰§è¡Œä¼šæŠ¥é”™ï¼Œä»…å‚è€ƒï¼‰:")
    print(run_command("uname -a"))
    
    # 2. NVIDIAé©±åŠ¨/CUDAä¿¡æ¯
    print("\nã€2. NVIDIAé©±åŠ¨ä¸CUDAä¿¡æ¯ã€‘")
    print("nvidia-smiè¾“å‡º:")
    nvidia_smi = run_command("nvidia-smi")
    print(nvidia_smi[:500] + "..." if len(nvidia_smi) > 500 else nvidia_smi)
    
    print("\nç³»ç»ŸCUDAç‰ˆæœ¬ï¼ˆWSLä¾§å®‰è£…çš„CUDA Toolkitï¼‰:")
    print(run_command("nvcc --version | grep release || echo 'æœªå®‰è£…nvcc'"))
    
    # 3. PyTorchæ·±åº¦ç‰ˆæœ¬ä¿¡æ¯
    print("\nã€3. PyTorchè¯¦ç»†ç‰ˆæœ¬ã€‘")
    print(f"PyTorchåŸºç¡€ç‰ˆæœ¬: {torch.__version__}")
    print(f"PyTorchç¼–è¯‘CUDAç‰ˆæœ¬: {torch.version.cuda}")
    print(f"PyTorch cuDNNç‰ˆæœ¬: {torch.backends.cudnn.version() if torch.cuda.is_available() else 'N/A'}")
    # æ³¨é‡Šæ‰PyTorch 1.12.1ä¸æ”¯æŒçš„è¡Œ
    # print(f"PyTorchæ˜¯å¦ä¸ºCUDAæ„å»º: {torch._C._cuda_is_built()}")
    print(f"CUDAæ˜¯å¦å¯ç”¨: {torch.cuda.is_available()}")
    print(f"PyTorchå®‰è£…è·¯å¾„: {torch.__file__}")
    
    # 4. ç¯å¢ƒå˜é‡æ£€æŸ¥
    print("\nã€4. å…³é”®ç¯å¢ƒå˜é‡ã€‘")
    print(f"LD_LIBRARY_PATH: {os.environ.get('LD_LIBRARY_PATH', 'æœªè®¾ç½®')}")
    print(f"CUDA_HOME: {os.environ.get('CUDA_HOME', 'æœªè®¾ç½®')}")
    print(f"PATHä¸­çš„CUDAè·¯å¾„: {[p for p in os.environ.get('PATH','').split(':') if 'cuda' in p.lower()]}")
    
    # 5. Condaç¯å¢ƒä¿¡æ¯
    print("\nã€5. Condaè™šæ‹Ÿç¯å¢ƒã€‘")
    print(f"å½“å‰Condaç¯å¢ƒ: {os.environ.get('CONDA_DEFAULT_ENV', 'æœªæ¿€æ´»Conda')}")
    print("Condaå·²å®‰è£…åŒ…ï¼ˆPyTorchç›¸å…³ï¼‰:")
    print(run_command("conda list | grep -E 'torch|cuda' || echo 'Condaæœªæ‰¾åˆ°ç›¸å…³åŒ…'"))

if __name__ == "__main__":
    # é…ç½®WSL GPUåº“è·¯å¾„
    os.environ["LD_LIBRARY_PATH"] = "/usr/lib/wsl/lib:" + os.environ.get("LD_LIBRARY_PATH", "")
    check_all_versions()